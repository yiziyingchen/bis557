cover.prob[i,1,j]<-mean(lower.exact<=p.vector[i] & upper.exact>=p.vector[i])
cover.prob[i,2,j]<-mean(lower.asym<=p.vector[i] & upper.asym>=p.vector[i])
cover.prob[i,3,j]<-mean(lower.cc<=p.vector[i] & upper.cc>=p.vector[i])
}
}
return(cover.prob) #return the array
}
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = c(0,1), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
}
}
#Call coverage
plot.coverage(n = 40)
plot.coverage(n = c(10,20,30))
plot.coverage(n = seq(10,80, by =10))
plot.coverage(n = c(25,50,100,200))
range(as.data.frame(coverage(n.vector = n[1]))[,1])
range(as.data.frame(coverage(n.vector = n[1]))[,2])
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = range(y), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
}
}
#Call coverage
plot.coverage(n = 40)
plot.coverage(n = c(10,20,30))
plot.coverage(n = c(25,50,100,200))
#Call coverage
plot.coverage(n = 40)
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = range(as.data.frame(coverage(n.vector = n[j]))[,2]), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
}
}
#Call coverage
plot.coverage(n = 40)
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = c(0,1), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
}
}
#Call coverage
plot.coverage(n = 40)
coverage(10)
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = c(0,1), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
legend("bottomright", legend=c("Exact", "Asymptotic", "Continuity Corrected"), col=c(1,2,3), lty=1:3, lty = 1:3)
}
}
#Call coverage
plot.coverage(n = 40)
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = c(0,1), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
legend("bottomright", legend=c("Exact", "Asymptotic", "Continuity Corrected"), col=c(1,2,3), lty=1:3, lty = 1:3)
}
}
#Call coverage
plot.coverage(n = 40)
plot.coverage<-function(n){
set.seed(1998)
#Know number of columns for the plot
if(length(n)==1){par(mfrow=c(1,1)) #If n is only 1, then make a large figure
} else {
k=ceiling(length(n)/2) #Know number of columns for the plot
if(k>3) {stop("You may want to reduce the number of sample sizes for this iteration to less than 6")}
par(mfrow=c(2,k))
}
#par(mfrow=c(2,k))
#Loop through each of the sample sizes
#sampmean<-NULL
#x<-NULL
#x=replicate(nsims,rexp(n=n))
#sampmean<-apply(x,2, mean)
for (j in 1:length(n)){
plot(x = seq(0.01, 0.5, by=0.01), y = as.data.frame(coverage(n.vector = n[j]))[,1],
main=paste("Coverage Probability for 3 Methods n =",n[j]),
xlab = "True Probaility",ylab = "Coverage Probability", ylim = c(0,1), type = "l", col=1, lwd=1)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,2], col = 2, type = "l", lty = 2)
lines(x = seq(0.01,0.5, by = 0.01), as.data.frame(coverage(n[j]))[,3], col = 3, type = "l", lty = 3)
legend("bottomright", legend=c("Exact", "Asymptotic", "Continuity Corrected"), col=c(1,2,3), lty=1:3)
}
}
#Call coverage
plot.coverage(n = 40)
setwd( "/Users/yiziyingchen/Desktop/Townsend")
library("readxl")
pneu1 <- read_excel("AMR raw data.xlsx", sheet = 1)
pneu2 <- read_excel("AMR raw data.xlsx", sheet = 2)
pneu3 <- read_excel("AMR raw data.xlsx", sheet = 3)
View(pneu1)
pneu1 <- read_excel("AMR raw data.xlsx", sheet = 1)
View(pneu1)
PA <- read_excel("AMR raw data.xlsx", sheet = 1)
AB <- read_excel("AMR raw data.xlsx", sheet = 2)
KP <- read_excel("AMR raw data.xlsx", sheet = 3)
PA <- read_excel("AMR raw data.xlsx", sheet = 1)
pa.model <- glm(Isolates_PA ~ Resustance_PA, family="binomial", data = PA)
pa.model <- glm(Isolates_PA ~ Resistance_PA, family="binomial", data = PA)
setwd( "/Users/yiziyingchen/Desktop/Townsend")
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
View(pneu1)
pneu2 <- read_excel("pneu.xlsx", sheet = 2)
View(pneu2)
pneu3 <- read_excel("pneu.xlsx", sheet = 3)
View(pneu3)
pneu1$PA.freq = pneu1$Resistance_PA/pneu1$`MERCK Isolates_PA`
pneu1$PA.freq
setwd( "/Users/yiziyingchen/Desktop/Townsend")
library("readxl")
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
install.packages("readxl")
install.packages("readxl")
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
library("readxl")
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
pneu2 <- read_excel("pneu.xlsx", sheet = 2)
pneu3 <- read_excel("pneu.xlsx", sheet = 3)
colnames(pneu1)[1] <- "Type"
colnames(pneu2)[1] <- "Type"
colnames(pneu2)[1] <- "Type"
pneu1$PA.freq = pneu1$Resistance_PA/pneu1$`MERCK Isolates_PA`
pneu1$AB.freq = pneu1$`Resistance AB`/pneu1$Isolates_AB
pneu1$KP.freq = pneu1$Resistance_KP/pneu1$`Isolates_KP`
pneu2$PA.freq = pneu2$Resistance_PA/pneu2$`CDDEP Isolates_PA`
pneu2$AB.freq = pneu2$`Resistance AB`/pneu2$Isolates_AB
pneu2$KP.freq = pneu2$Resistance_KP/pneu2$`Isolates_KP`
pneu3$PA.iso = pneu3$`CDDEP Isolates_PA` + pneu3$`MERCK Isolates_PA`
pneu3$AB.iso = pneu3$Isolates_AB + pneu3$Isolates_AB__1
pneu3$KP.iso = pneu3$Isolates_KP + pneu3$Isolates_KP__1
pneu3$PA.resis = pneu3$Resistance_PA + pneu3$Resistance_PA__1
pneu3$AB.resis = pneu3$`Resistance AB` + pneu3$`Resistance AB__1`
pneu3$KP.resis = pneu3$Resistance_KP + pneu3$Resistance_KP__1
pneu3$PA.freq = pneu3$PA.resis/pneu3$PA.iso
pneu3$AB.freq = pneu3$AB.resis/pneu3$AB.iso
pneu3$KP.freq = pneu3$KP.resis/pneu3$KP.iso
fitPA.MERCK = lm(PA.freq ~ Consumption, data = pneu1)
summary(fitPA.MERCK)
fitPA.CDDEP = lm(PA.freq~Consumption, data = pneu2)
summary(fitPA.CDDEP)
summary(fitPA.CDDEP)
summary(fitPA.CDDEP)$Coefficients
summary(fitPA.CDDEP)$coefficients
summary(fitPA.CDDEP)$coefficients$Consumption
summary(fitPA.CDDEP)$coefficients[1]
summary(fitPA.CDDEP)$coefficients[2]
summary(fitPA.CDDEP)$coefficients
summary(fitPA.CDDEP)$coefficients[2]
pa.rt <- e^(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+e^(pa.rho*pneu2$Consumption+pa.theta_1))
pa.rt <- exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
pa.rt <- exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
fitKP.MERCK = lm(KP.freq~Consumption, data = pneu1.KP)
pneu1.1 <- pneu1[complete.cases(pneu1),]
pneu1.KP <- pneu1[is.finite(pneu1$KP.freq),]
pneu1.AB <- pneu1.1[is.finite(pneu1.1$AB.freq),]
#small sample size, leading to biased correlation result
length(pneu1.AB)
fitAB.MERCK = lm(AB.freq ~Consumption, data = pneu1.AB)
summary(fitAB.MERCK)
setwd( "/Users/yiziyingchen/Desktop/Townsend")
library("readxl")
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
pneu1
fitPA.MERCK = lm(PA.freq ~ Consumption, data = pneu1)
pneu1 <- read_excel("pneu.xlsx", sheet = 1)
pneu2 <- read_excel("pneu.xlsx", sheet = 2)
pneu3 <- read_excel("pneu.xlsx", sheet = 3)
View(pneu1)
colnames(pneu1)[1] <- "Type"
colnames(pneu2)[1] <- "Type"
colnames(pneu2)[1] <- "Type"
pneu1$PA.freq = pneu1$Resistance_PA/pneu1$`MERCK Isolates_PA`
pneu1$AB.freq = pneu1$`Resistance AB`/pneu1$Isolates_AB
pneu1$KP.freq = pneu1$Resistance_KP/pneu1$`Isolates_KP`
pneu2$PA.freq = pneu2$Resistance_PA/pneu2$`CDDEP Isolates_PA`
pneu2$AB.freq = pneu2$`Resistance AB`/pneu2$Isolates_AB
pneu2$KP.freq = pneu2$Resistance_KP/pneu2$`Isolates_KP`
pneu3$PA.iso = pneu3$`CDDEP Isolates_PA` + pneu3$`MERCK Isolates_PA`
pneu3$AB.iso = pneu3$Isolates_AB + pneu3$Isolates_AB__1
pneu3$KP.iso = pneu3$Isolates_KP + pneu3$Isolates_KP__1
pneu3$PA.resis = pneu3$Resistance_PA + pneu3$Resistance_PA__1
pneu3$AB.resis = pneu3$`Resistance AB` + pneu3$`Resistance AB__1`
pneu3$KP.resis = pneu3$Resistance_KP + pneu3$Resistance_KP__1
pneu3$PA.freq = pneu3$PA.resis/pneu3$PA.iso
pneu3$AB.freq = pneu3$AB.resis/pneu3$AB.iso
pneu3$KP.freq = pneu3$KP.resis/pneu3$KP.iso
fitPA.MERCK = lm(PA.freq ~ Consumption, data = pneu1)
summary(fitPA.MERCK)
pneu1.1 <- pneu1[complete.cases(pneu1),]
pneu1.KP <- pneu1[is.finite(pneu1$KP.freq),]
pneu1.AB <- pneu1.1[is.finite(pneu1.1$AB.freq),]
#small sample size, leading to biased correlation result
length(pneu1.AB)
fitAB.MERCK = lm(AB.freq ~Consumption, data = pneu1.AB)
summary(fitAB.MERCK)
fitKP.MERCK = lm(KP.freq~Consumption, data = pneu1.KP)
summary(fitKP.MERCK)
fitPA.CDDEP = lm(PA.freq~Consumption, data = pneu2)
summary(fitPA.CDDEP)$coefficients
pa.rho = summary(fitPA.CDDEP)$coefficients[2]
pa.theta_1 = summary(fitPA.CDDEP)$coefficients[1]
fitAB.CDDEP = lm(AB.freq~Consumption, data = pneu2)
summary(fitAB.CDDEP)
ab.rho = summary(fitAB.CDDEP)$coefficients[2]
ab.theta_1 = summary(fitAB.CDDEP)$coefficients[1]
fitKP.CDDEP = lm(KP.freq~Consumption, data = pneu2)
summary(fitKP.CDDEP)
kp.rho = summary(fitKP.CDDEP)$coefficients[2]
kp.theta_1 = summary(fitKP.CDDEP)$coefficients[1]
pa.rt <- exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
for r0 in (0:1){
for (r0 in 0:1){
pa.rt <- exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
}
?dbinom
for (r0 in 0:1){
pa.rt <- exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
}
pa.rt
pa.rho*pneu2$Consumption
pa.rho*pneu2$Consumption+pa.theta_1)
pa.rho*pneu2$Consumption+pa.theta_1
1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1)
for (r0 in 0:1){
pa.rt <- exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
pa.rt
}
pa.rt
for (r0 in 0:1){
exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1))
}
for (r0 in 0:1){
pa.rt <- solve(exp(pa.rho*pneu2$Consumption+pa.theta_1)/(1/r0-1+exp(pa.rho*pneu2$Consumption+pa.theta_1)))
}
pa.m <- pa.rho*pneu2$Consumption+pa.theta_1
for (r0 in 0:1){
pa.rt <- exp(pa.m)/(1/r0-1+exp(pa.m))
}
library(stats4)
mle(LL, start = list(mu = 1, sigma=1))
library(stats4)
mle(bi, start = list(r0 = 0, m=1))
bi <- function(r0, m){
R <- dbinom(x, 1000, r0)
}
library(stats4)
mle(bi, start = list(r0 = 0, m=1))
library(keras)
# Data Preparation -----------------------------------------------------
batch_size <- 128
num_classes <- 10
epochs <- 2
# Input image dimensions
img_rows <- 28
img_cols <- 28
# The data, shuffled and split between train and test sets
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
# Redefine  dimension of train/test inputs
x_train <- array_reshape(x_train, c(nrow(x_train), img_rows, img_cols, 1))
x_test <- array_reshape(x_test, c(nrow(x_test), img_rows, img_cols, 1))
input_shape <- c(img_rows, img_cols, 1)
# Transform RGB values into [0,1] range
x_train <- x_train / 255
x_test <- x_test / 255
cat('x_train_shape:', dim(x_train), '\n')
cat(nrow(x_train), 'train samples\n')
cat(nrow(x_test), 'test samples\n')
# Convert class vectors to binary class matrices
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
# Define Model -----------------------------------------------------------
# Define model
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
# Compile model
model %>% compile(
loss = loss_categorical_crossentropy,
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
# Train model
model %>% fit(
x_train, y_train,
batch_size = batch_size,
epochs = epochs,
validation_split = 0.2
)
model %>% fit(
x_test, y_test,
batch_size = batch_size,
epochs = epochs,
validtaion_split = 0.2
)
scores <- model %>% evaluate(
x_test, y_test, verbose = 0
)
l <- model %>% evaluate(
x_train, y_train, verbose = 0
)
# Output metrics
cat('Test loss:', scores[[1]], '\n')
cat('Test accuracy:', scores[[2]], '\n')
cat('Train loss:', l[[1]], '\n')
cat('Train accuracy:', l[[2]], '\n')
library(keras)
# Data Preparation -----------------------------------------------------
batch_size <- 128
num_classes <- 10
epochs <- 2
# Input image dimensions
img_rows <- 28
img_cols <- 28
# The data, shuffled and split between train and test sets
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
# Redefine  dimension of train/test inputs
x_train <- array_reshape(x_train, c(nrow(x_train), img_rows, img_cols, 1))
x_test <- array_reshape(x_test, c(nrow(x_test), img_rows, img_cols, 1))
input_shape <- c(img_rows, img_cols, 1)
# Transform RGB values into [0,1] range
x_train <- x_train / 255
x_test <- x_test / 255
cat('x_train_shape:', dim(x_train), '\n')
cat(nrow(x_train), 'train samples\n')
cat(nrow(x_test), 'test samples\n')
# Convert class vectors to binary class matrices
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
# Define Model -----------------------------------------------------------
# Define model
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
# Compile model
model %>% compile(
loss = loss_categorical_crossentropy,
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
# Train model
model %>% fit(
x_train, y_train,
batch_size = batch_size,
epochs = epochs,
validation_split = 0.2
)
getwd()
setwd("/Users/yiziyingchen/Desktop/bis557")
check()
library(devtools)
check()
check()
check()
check()
library(e1071)
sd(x_train)
library(e1071)
sd(x_train)
mean(x_train)
kurtosis(x_train)
sd(x_test)
mean(x_test)
kurtosis(x_test)
check()
check()
check()
check()
remove.packages(keras)
remove.packages("keras")
check()
devtools::check()
check()
installed.packages(keras)
keras
library(keras)
remove.packages("keras")
remove(keras)
rm(keras)
rm(list=ls())
